{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url, catag, fieldnames):\n",
    "    \n",
    "    with open('文本聚类数据2.csv', 'a', newline='', encoding='utf-8-sig') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile,fieldnames)\n",
    "\n",
    "        browser = webdriver.Chrome()\n",
    "        browser.implicitly_wait(5) # 隐式等待\n",
    "        title_text_list = []\n",
    "        for i in range(1,51):\n",
    "            new_url = url+str(i) # 更新url\n",
    "            browser.get(new_url) # 获取网页源码\n",
    "            for j in range(1,11):\n",
    "                for k in range(1,6):\n",
    "                    title_text = browser.find_element_by_xpath('//ul[%d]//li[%d]//span[@class=\"c_tit\"]/a'%(j,k)).text # 用xpath匹配目标文本\n",
    "                    title_text_list.append(title_text)\n",
    "                \n",
    "            time.sleep(1) # 睡一秒\n",
    "            browser.find_element_by_xpath('//span[@class=\"pagebox_pre\"]//a[text()=\"下一页\"]').click() # 模拟点击实现翻页\n",
    "        # 写入csv文件\n",
    "        for i in range(len(title_text_list)):\n",
    "            writer.writerow({'类别': catag, '文本': title_text_list[i]})\n",
    "\n",
    "        browser.quit()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主函数\n",
    "if __name__ == '__main__':  \n",
    "    url1 = 'https://news.sina.com.cn/roll/#pageid=153&lid=2513&k=&num=50&page='\n",
    "    url2 = 'https://news.sina.com.cn/roll/#pageid=153&lid=2514&k=&num=50&page='\n",
    "    url3 = 'https://news.sina.com.cn/roll/#pageid=153&lid=2515&k=&num=50&page='\n",
    "    url4 = 'https://news.sina.com.cn/roll/#pageid=153&lid=2516&k=&num=50&page='\n",
    "    url = [url1,url2,url3,url4]\n",
    "    print(url)\n",
    "    catagory = ['娱乐','军事','科技','财经']\n",
    "    # 创建csv文件\n",
    "    with open('文本聚类数据.csv', 'a', newline='', encoding='utf-8-sig') as csvfile:\n",
    "        fieldnames = ['类别', '文本']   \n",
    "        f_csv = csv.writer(csvfile)\n",
    "        f_csv.writerow(fieldnames)\n",
    "    for i in range(4):\n",
    "        get_data(url[i],catagory[i],fieldnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv转为txt\n",
    "with open('data.csv', 'r') as f_in, open('data.txt', 'w') as f_out:\n",
    "    content = f_in.read().replace(',', ' ')\n",
    "    f_out.write(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
